{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "import numpy as np \n",
    "import random \n",
    "import os\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SEED = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to(obj, device):\n",
    "    if torch.is_tensor(obj):\n",
    "        return obj.to(device)\n",
    "    elif isinstance(obj, dict):\n",
    "        res = {}\n",
    "        for k, v in obj.items():\n",
    "            res[k] = move_to(v, device)\n",
    "        return res\n",
    "    elif isinstance(obj, list):\n",
    "        res = []\n",
    "        for v in obj:\n",
    "            res.append(move_to(v, device))\n",
    "        return res\n",
    "    else:\n",
    "        raise TypeError(\"Invalid type for move_to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_cifar = transforms.Compose([\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "transforms_imagenet = transforms.Compose([\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.base = timm.create_model('rexnet_150', num_classes=1,  pretrained=pretrained)\n",
    "        self.base.head.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1920, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        q = self.fc1(x)\n",
    "        z = self.relu(q)\n",
    "        z = self.fc2(z)\n",
    "\n",
    "        q = F.normalize(q, dim=1)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        return x, h, z\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pred = nn.Linear(512, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, x, _ = self.model(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pred(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(transfer=False, pretrained=False):\n",
    "    if transfer:\n",
    "        model = Model(pretrained=True)\n",
    "    else:\n",
    "        model = Model()\n",
    "            \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.load(\"best_model_rexnet.pt\"))\n",
    "\n",
    "    classifier = Classifier(model)\n",
    "    classifier.to(DEVICE)\n",
    "\n",
    "    for name, param in classifier.named_parameters():\n",
    "        if \"model\" in name:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_dl(dataset, frac):\n",
    "#     n_samples = len(dataset)\n",
    "#     n_samples_out = int(frac * n_samples)\n",
    "#     indices = np.random.choice(n_samples, n_samples_out, replace=False)\n",
    "#     ds = torch.utils.data.Subset(dataset, indices)\n",
    "#     return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, dl, optimizer, criterion, transforms):\n",
    "    model.train()\n",
    "    n_samples = 0\n",
    "\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dl):\n",
    "        X, y = batch\n",
    "        X = move_to(X, DEVICE)\n",
    "        y = move_to(y, DEVICE)\n",
    "        \n",
    "        X = transforms(X)\n",
    "\n",
    "        predictions = model(X)\n",
    "\n",
    "        loss = criterion(predictions, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        n_samples += X.shape[0]\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(predictions, dim=1)\n",
    "        correct += torch.sum(predictions == y).item()\n",
    "\n",
    "    average_loss = total_loss / n_samples\n",
    "    average_accuracy = correct / n_samples\n",
    "    return average_loss, average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(model, dl, criterion, transforms):\n",
    "    model.eval()\n",
    "    n_samples = 0\n",
    "\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl):\n",
    "            X, y = batch\n",
    "            X = move_to(X, DEVICE)\n",
    "            y = move_to(y, DEVICE)\n",
    "            \n",
    "            X = transforms(X)\n",
    "\n",
    "            predictions = model(X)\n",
    "\n",
    "            loss = criterion(predictions, y)\n",
    "\n",
    "            n_samples += X.shape[0]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "            correct += torch.sum(predictions == y).item()\n",
    "\n",
    "        average_loss = total_loss / n_samples\n",
    "        average_accuracy = correct / n_samples\n",
    "    return average_loss, average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_folds(min_epochs=10, max_epochs=50, min_acc=0.95, fracs=[0.01, 0.1, 1], folds=5, test=False,\n",
    "                   unfreeze_epoch=1, batch_size=90):\n",
    "    classifier_names = ['Supervised', 'Transfer']\n",
    "    \n",
    "    if test:\n",
    "        classifiers = [get_model(), get_model(transfer=True)]\n",
    "    else:\n",
    "        classifiers = [get_model(), get_model(transfer=True), get_model(pretrained=True)]\n",
    "        classifier_names.append('Semi-Supervised')\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    metrics = {classifier_name:{f\"frac_{frac}\":{f\"fold_{fold}\":{'acc_train':0, 'acc_test':0} for fold in range(1, folds+1)} for frac in fracs} for classifier_name in classifier_names}\n",
    "    \n",
    "    SEED = 42\n",
    "\n",
    "    ds_train = torchvision.datasets.CIFAR10('data', download=True, transform = transforms.ToTensor())\n",
    "    ds_test = torchvision.datasets.CIFAR10('data', train=False, download=True, transform = transforms.ToTensor())\n",
    "\n",
    "    ds_combined = torch.utils.data.ConcatDataset((ds_train,ds_test))\n",
    "    \n",
    "    if test:\n",
    "        ds_combined =  torch.utils.data.Subset(ds_combined, range(folds*2))\n",
    "        batch_size = 2\n",
    "    \n",
    "    classifier_metrics = []\n",
    "    for classifier_name, classifier in zip(classifier_names, classifiers):\n",
    "        # save initial model parameters to reuse on every fold\n",
    "        #initial_parameters = classifier.state_dict().copy()\n",
    "        torch.save(classifier.state_dict(), f\"initial_parameters.pt\")\n",
    "        \n",
    "        if classifier_name == 'Transfer':\n",
    "            transformations = transforms_cifar\n",
    "        else:\n",
    "            transformations = transforms_imagenet\n",
    "                \n",
    "        \n",
    "        print(\"---------------------------------------\")\n",
    "        print(f\"Training classifier: {classifier_name}\")\n",
    "        for frac in fracs:\n",
    "            print(f\"  Training on {frac*100}% of training data\")\n",
    "            kf = KFold(n_splits=folds, shuffle=True)\n",
    "            \n",
    "            for fold_number, indices in enumerate(kf.split(ds_combined), start=1):\n",
    "                print(f\"  Fold {fold_number}\")\n",
    "                print(\"---------------------------------------\")\n",
    "                train_idx, test_idx = indices\n",
    "                train_idx = np.random.choice(train_idx, int(np.ceil(len(train_idx)*frac)), replace=False) \n",
    "                \n",
    "                ds_train = torch.utils.data.Subset(ds_combined, train_idx)\n",
    "                ds_test = torch.utils.data.Subset(ds_combined, test_idx)\n",
    "                \n",
    "                dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "                dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "                \n",
    "                #classifier.load_state_dict(initial_parameters)\n",
    "                classifier.load_state_dict(torch.load(\"initial_parameters.pt\"))\n",
    "\n",
    "                optimizer = torch.optim.AdamW(classifier.parameters())\n",
    "\n",
    "                best_acc_train = 0\n",
    "                best_acc_test = 0\n",
    "                epoch = 0\n",
    "                while (best_acc_train < min_acc or epoch < min_epochs) and epoch < max_epochs:\n",
    "                    if epoch == 1:\n",
    "                        for name, param in classifier.named_parameters():\n",
    "                            param.requires_grad = True\n",
    "\n",
    "                    loss_train, acc_train = train_fn(classifier, dl_train, optimizer, criterion, transformations)\n",
    "                    loss_test, acc_test = test_fn(classifier, dl_test, criterion, transformations)\n",
    "                    \n",
    "                    if acc_train > best_acc_train:\n",
    "                        best_acc_train = acc_train\n",
    "                    if acc_test > best_acc_test:\n",
    "                        best_acc_test = acc_test\n",
    "                    \n",
    "                    epoch += 1\n",
    "\n",
    "                    print(f\"  Epoch: {epoch}\")\n",
    "                    print(\"  Training metrics\")\n",
    "                    print(f\"    loss_train: {loss_train}\")\n",
    "                    print(f\"    acc_train: {acc_train}\")\n",
    "                    print(f\"    loss_test: {loss_test}\")\n",
    "                    print(f\"    acc_test: {acc_test}\")\n",
    "                    print()\n",
    "                \n",
    "                metrics[classifier_name][f\"frac_{frac}\"][f\"fold_{fold_number}\"]['acc_train'] = best_acc_train\n",
    "                metrics[classifier_name][f\"frac_{frac}\"][f\"fold_{fold_number}\"]['acc_test'] = best_acc_test\n",
    "\n",
    "    return metrics            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = finetune_folds(folds=10)\n",
    "with open(f\"metrics_150.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"metrics_150.pkl\", \"rb\") as g:\n",
    "    metrics = pickle.load(g)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
