{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"z_vs_q.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2 = dataframe.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=['Unnamed: 7', col2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(data, stepsize=10):\n",
    "    cumsum = []\n",
    "    \n",
    "    for i in range(0, len(data), stepsize):\n",
    "        cumsum.append(sum(data[i:i+stepsize]))\n",
    "\n",
    "    cumsum=np.array(cumsum)/stepsize\n",
    "    return cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "data = dataframe.to_numpy()[:, 1:]\n",
    "\n",
    "summed = get_sum(data, 10)\n",
    "\n",
    "jump_size = 10\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(np.array([jump_size*np.arange(50)]).T, summed[:50])\n",
    "\n",
    "ax.set_ylabel('Test accuracy', fontsize=20)\n",
    "ax.set_xlabel(\"Epochs\", fontsize=20)\n",
    "ax.legend([\"ResNet34 z\", \"ResNet50 z\", \"RexNet150 z\", \"ResNet34 q\", \"ResNet50 q\", \"RexNet150 q\"], fontsize=25)\n",
    "ax.set_title(\"KNN accuracy by Layer\",fontsize=40)\n",
    "\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "plt.savefig(\"z_vs_q.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"train_loss.csv\")\n",
    "\n",
    "data = dataframe.to_numpy()[:, 1:]\n",
    "\n",
    "jump_size = 10\n",
    "\n",
    "summed = get_sum(data, jump_size)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# ax.plot(np.array([jump_size*np.arange(len(summed))]).T, summed)\n",
    "ax.plot(np.array([jump_size*np.arange(50)]).T, summed[:50])\n",
    "\n",
    "ax.set_ylabel('Loss', fontsize=20)\n",
    "ax.set_xlabel(\"Epochs\", fontsize=20)\n",
    "ax.legend([\"RexNet150\", \"ResNet34\", \"ResNet50\"], fontsize=25)\n",
    "ax.set_title(\"Train Loss\",fontsize=40)\n",
    "\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "plt.savefig(\"train_loss.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy of finetuned models\n",
    "sns.set()\n",
    "with open(\"metrics_34.pkl\", \"rb\") as f:\n",
    "    metrics = pickle.load(f)\n",
    "\n",
    "performance_metrics = {}\n",
    "for model in metrics.keys():\n",
    "    for frac in metrics[model].keys():\n",
    "        avg = 0\n",
    "        for fold in metrics[model][frac].keys():\n",
    "            avg += metrics[model][frac][fold]['acc_test']\n",
    "        performance_metrics[model+' '+frac] = avg/10\n",
    "performance_metrics\n",
    "\n",
    "plt.rcParams['figure.figsize']=(14,14)\n",
    "N = 3\n",
    "performance_vals = [value for value in performance_metrics.values()]\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.27       # the width of the bars\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "base = [i for i in performance_vals[0:3]]\n",
    "rects2 = ax.bar(ind, base, width, color='g')\n",
    "transfer = [i for i in performance_vals[3:6]]\n",
    "rects3 = ax.bar(ind+width, transfer, width, color='b')\n",
    "pre = [i for i in performance_vals[6:]]\n",
    "rects1 = ax.bar(ind+width*2, pre, width, color='r')\n",
    "\n",
    "ax.set_ylabel('Test accuracy', fontsize=30)\n",
    "ax.set_xlabel(\"Amount of labelled data\", fontsize=30)\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( ('1%', '10%', '100%'), fontsize=30)\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_yticks(np.linspace(0,1,11,endpoint=True))\n",
    "ax.set_yticklabels(np.round(np.linspace(0,1,11,endpoint=True),2), fontsize=25)\n",
    "ax.legend((rects2[0], rects3[0], rects1[0]), ('Supervised', 'Transfer','Semi-Supervised'), loc='upper left', fontsize=25)\n",
    "ax.set_title(\"ResNet34\",fontsize=50)\n",
    "\n",
    "for rect in rects1 + rects2 + rects3:\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width() / 2.0, height, f\"{height:.2f}\", ha='center', va='bottom', fontsize=23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "seed_everything(7)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "ds_train = torchvision.datasets.CIFAR10('data', download=True, transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "sample_dl = torch.utils.data.DataLoader(ds_train, batch_size=2)\n",
    "X = next(iter(sample_dl))[0][0]\n",
    "resize = torchvision.transforms.Resize((128,128))\n",
    "X = resize(X)\n",
    "X1 = train_transform(X)\n",
    "X2 = train_transform(X)\n",
    "image_data1 = torch.permute(X, (1,2,0)).numpy()\n",
    "plt.imshow(image_data1)\n",
    "plt.imsave(\"Image1.png\",image_data1)\n",
    "plt.show()\n",
    "X1 = resize(X1)\n",
    "X1 = torch.permute(X1, (1,2,0)).numpy()\n",
    "X1_mask = np.zeros((128,128))\n",
    "transform_data1 = cv2.normalize(X1, X1_mask, 0, 1, cv2.NORM_MINMAX)\n",
    "transform_data1 = np.clip(transform_data1, 0, 1)\n",
    "# transform_data1 = resize(transform_data1, (128,128))\n",
    "# print(transform_data1.min(), transform_data1.max())\n",
    "plt.imshow(transform_data1)\n",
    "plt.imsave(\"Image1T1.png\",transform_data1)\n",
    "plt.show()\n",
    "X2 = resize(X2)\n",
    "X2 = torch.permute(X2, (1,2,0)).numpy()\n",
    "X2_mask = np.zeros((128,128))\n",
    "transform_data2 = cv2.normalize(X2, X2_mask, 0, 1, cv2.NORM_MINMAX)\n",
    "transform_data2 = np.clip(transform_data2, 0, 1)\n",
    "# transform_data2 = resize(transform_data2, (128,128))\n",
    "plt.imshow(transform_data2)\n",
    "plt.imsave(\"Image1T2.png\", transform_data2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "Y = next(iter(sample_dl))[0][1]\n",
    "Y = resize(Y)\n",
    "Y1 = train_transform(Y)\n",
    "Y2 = train_transform(Y)\n",
    "image_data2 = torch.permute(Y, (1,2,0)).numpy()\n",
    "plt.imshow(image_data2)\n",
    "plt.imsave(\"Image2.png\", image_data2)\n",
    "plt.show()\n",
    "\n",
    "Y1 = resize(Y1)\n",
    "Y1 = torch.permute(Y1, (1,2,0)).numpy()\n",
    "Y1_mask = np.zeros((128,128))\n",
    "transform_data1 = cv2.normalize(Y1, Y1_mask, 0, 1, cv2.NORM_MINMAX)\n",
    "transform_data1 = np.clip(transform_data1, 0, 1)\n",
    "plt.imshow(transform_data1)\n",
    "plt.imsave(\"Image2T1.png\",transform_data1)\n",
    "plt.show()\n",
    "\n",
    "Y2 = resize(Y2)\n",
    "Y2 = torch.permute(Y2, (1,2,0)).numpy()\n",
    "Y2_mask = np.zeros((128,128))\n",
    "transform_data2 = cv2.normalize(Y2, Y2_mask, 0, 1, cv2.NORM_MINMAX)\n",
    "transform_data2 = np.clip(transform_data2, 0, 1)\n",
    "plt.imshow(transform_data2)\n",
    "plt.imsave(\"Image2T2.png\", transform_data2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
